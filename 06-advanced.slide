# Advanced
Course Go
Tags: golang, go

## Outline

TODO

## Simple but useful performance improvements in Go

- Go compiler is pretty straightfoward (= dumb)
- It needs some help from developers

## Some interesting areas backed by experience

1. Pass structures by reference, not by value
2. Pass receivers by reference, not by value
3. Maps pre-allocation
4. Arrays vs slices

- Most things mentioned above are not idiomatic!

## Pass structures by reference, not by value

- All data types are passed by value into functions and methods
    - that's good from "state-space" perspective
    - not so good from performance point of view
- Java/Python have different semantic!
- And no nice solution like `const` and `mut` exists in Go

## Problem definition

- Large structures passed by value everywhere in the code
    - even within inner loops
- It causes overhead that is super easy to avoid
    - but at cost: wrong semantic is used

## Real example

```toml
[logging]
debug = true
log_level = "info"

[kafka_broker]
enabled = true
address = "kafka:29092" #provide in deployment env or as secret
security_protocol = "PLAINTEXT"
cert_path = "not-set"
sasl_mechanism = "PLAIN"
sasl_username = "not-used"
sasl_password = "not-used"
topic = "platform.notifications.ingress" #provide in deployment env or as secret
timeout = "60s"
likelihood_threshold = 0
impact_threshold = 0
severity_threshold = 0
total_risk_threshold = 3
event_filter = "totalRisk >= totalRiskThreshold"

[service_log]
client_id = "a-service-id"
client_secret = "a-secret"
token_url = ""
enabled = false
url = "https://api.openshift.com/api/service_logs/v1/cluster_logs/"
timeout = "15s"
likelihood_threshold = 0
impact_threshold = 0
severity_threshold = 0
total_risk_threshold = 0
event_filter = "totalRisk >= totalRiskThreshold"
rule_details_uri = "https://console.redhat.com/openshift/insights/advisor/recommendations/{module}|{error_key}"

[storage]
db_driver = "postgres"
pg_username = "postgres" #provide in deployment env or as secret
pg_password = "postgres" #provide in deployment env or as secret
pg_host = "localhost" #provide in deployment env or as secret
pg_port = 5432 #provide in deployment env or as secret
pg_db_name = "notification" #provide in deployment env or as secret
pg_params = "sslmode=disable"
log_sql_queries = true

[dependencies]
content_server = "localhost:8082" #provide in deployment env or as secret
content_endpoint = "/api/v1/content" #provide in deployment env or as secret
template_renderer_server = "localhost:8083" #provide in deployment env or as secret
template_renderer_endpoint = "/v1/rendered_reports" #provide in deployment env or as secret

[notifications]
insights_advisor_url = "https://console.redhat.com/openshift/insights/advisor/clusters/{cluster_id}"
cluster_details_uri = "https://console.redhat.com/openshift/details/{cluster_id}#insights"
rule_details_uri = "https://console.redhat.com/openshift/details/{cluster_id}/insights/{module}/{error_key}"
# valid units are SQL epoch time units: months days hours minutes seconds"
cooldown = "24 hours"

[metrics]
job_name = "ccx_notification_service"
# The metrics in Prometheus will be $namespace_$subsystem_$name
namespace = "ccx_notification_service"
subsystem = "to_notification_backend"
gateway_url = "localhost:9091"
gateway_auth_token = ""
retries = 3
# Valid time units are "ns", "us" (or "Âµs"), "ms", "s", "m", "h".
retry_after = "60s"

[cleaner]
# valid units are SQL epoch time units: months days hours minutes seconds"
max_age = "90 days"

[processing]
filter_allowed_clusters = false
allowed_clusters = []
filter_blocked_clusters = false
blocked_clusters = []
```

## Representation of such structure in Go

.code assets/lecture-05/config_struct_1.go

## Sub-structure(s)

.code assets/lecture-05/config_struct_2.go

.code assets/lecture-05/config_struct_3.go

## 'Getter' used in the code

```go
func GetStorageConfigurationByValue(configuration ConfigStruct) StorageConfiguration {
        return configuration.Storage
}
```

- Pros
    - pretty idiomatic
    - basically say the struct is immutable on 1st level
- Cons
    - structure is passed by value
    - structure size is about 700 bytes!

## Dirty solution

- the only solution possible in Go
    - different semantic:
        - passing by reference -> struct can be changed within
- unfortunately we can't distinguish between `const` and `mut`
    - mutation (or no mutation) has to be checked by unit tests

```go
func GetStorageConfigurationByReference(configuration *ConfigStruct) StorageConfiguration {
        return configuration.Storage
}
```

## Is it worth to do it?

.code assets/lecture-05/benchmark_1_1.go

## Helper function to load configuration

.code assets/lecture-05/benchmark_1_2.go

## Helper function to load configuration

.code assets/lecture-05/benchmark_1_3.go

## Actual benchmarks

.code assets/lecture-05/benchmark_1_4.go

## Benchmark results

```
$ go test -bench=. -benchtime=1000000000x -cpuprofile profile.out -v config-struct/conf

goos: linux
goarch: amd64
pkg: config-struct/conf
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkGetStorageConfigurationFunctionByValue
BenchmarkGetStorageConfigurationFunctionByValue-8       1000000000  13.20 ns/op
BenchmarkGetStorageConfigurationFunctionByReference
BenchmarkGetStorageConfigurationFunctionByReference-8   1000000000   0.2405 ns/op
PASS
ok      config-struct/conf      27.166s
```

## Benchmark results

- 13.20 ns/op vs 0.2405 ns/op
- That is 5488% speed increase :)
    - memcpy operation elimination

## Graphical output

![Benchmark1](images/benchmark1.png)

## Table output

![Benchmark1](images/benchmark2.png)

## Is it still relevant?

- 0.2405 ns vs. 13.20 ns from CPU point of view vs. human point of view

![CPU](images/computer_latency.png)

## Memory is getting "slower"

![CPU2](images/cpu.png)

## What about methods?

- The same issue + simple fix

```go
func (configuration ConfigStruct) GetStorageConfigurationByValue() StorageConfiguration {
        return configuration.Storage
}

func (configuration *ConfigStruct) GetStorageConfigurationByReference() StorageConfiguration {
        return configuration.Storage
}
```

## Benchmark for methods

```go
func BenchmarkGetStorageConfigurationMethodByValue(b *testing.B) {
        b.StopTimer()
        configuration := mustLoadBenchmarkConfiguration(b)
        b.StartTimer()

        for i := 0; i < b.N; i++ {
                configuration.GetStorageConfigurationByValue()
        }
}

func BenchmarkGetStorageConfigurationMethodByReference(b *testing.B) {
        b.StopTimer()
        configuration := mustLoadBenchmarkConfiguration(b)
        b.StartTimer()

        for i := 0; i < b.N; i++ {
                configuration.GetStorageConfigurationByReference()
        }
}
```

## Run the benchmark

```
$ go test -bench=. -benchtime=1000000000x -cpuprofile profile.out -v config-struct/conf

goos: linux
goarch: amd64
pkg: config-struct/conf
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkGetStorageConfigurationFunctionByValue
BenchmarkGetStorageConfigurationFunctionByValue-8      1000000000   13.20 ns/op
BenchmarkGetStorageConfigurationFunctionByReference
BenchmarkGetStorageConfigurationFunctionByReference-8  1000000000    0.2405 ns/op
BenchmarkGetStorageConfigurationMethodByValue
BenchmarkGetStorageConfigurationMethodByValue-8        1000000000   13.24 ns/op
BenchmarkGetStorageConfigurationMethodByReference
BenchmarkGetStorageConfigurationMethodByReference-8    1000000000    0.3596 ns/op
PASS
ok      config-struct/conf      27.166s
```

## Maps pre-allocation

- In Go it is possible to specify number of map items during map allocation

```go
m1 := make(map[UUID]time.Time)
m2 := make(map[UUID]time.Time, b.N)
```

- Not strictly needed, so developers took "Python approach"
- Does it make sense to try to estimate number of items?
- Who knows? Probably only the benchmark...

## Benchmark

```go
type UUID string

func BenchmarkInsertIntoPreallocatedMapUUIDKey(b *testing.B) {
        m := make(map[UUID]time.Time, b.N)
        t := time.Now()

        for i := 0; i < b.N; i++ {
                b.StopTimer()
                id := UUID(uuid.New().String())
                b.StartTimer()
                m[id] = t
        }
}

func BenchmarkInsertIntoEmptyMapUUIDKey(b *testing.B) {
        m := map[UUID]time.Time{}
        t := time.Now()

        for i := 0; i < b.N; i++ {
                b.StopTimer()
                id := UUID(uuid.New().String())
                b.StartTimer()
                m[id] = t
        }
}
```

## Benchmark results

```
goos: linux
goarch: amd64
pkg: map-bench
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkInsertIntoEmptyMapUUIDKey-8            1000000   354.7 ns/op
BenchmarkInsertIntoPreallocatedMapUUIDKey-8     1000000   163.9 ns/op
PASS
```

## Graphical output

![Profiler1](images/profiler1.png)

## Maps with large keys

- Keys can be of any type in Go
- So keys might be pretty large (imagine structs)

```go
type key struct {
        ID      int
        payload [100]byte
}

m1 := make(map[key]value)
m2 := make(map[key]value, capacity)
```

## Benchmark

```go
type key struct {
        ID      int
        payload [100]byte
}
type value struct{}

func BenchmarkInsertIntoPreallocatedMapCompoundKey(b *testing.B) {
        m := make(map[key]value, b.N)
        for i := 0; i < b.N; i++ {
                k := key{
                        ID: i,
                }
                m[k] = value{}
        }
}

func BenchmarkInsertIntoEmptyMapCompoundKey(b *testing.B) {
        m := map[key]value{}
        for i := 0; i < b.N; i++ {
                k := key{
                        ID: i,
                }
                m[k] = value{}
        }
}
```

## Benchmark results for maps with large keys

```
goos: linux
goarch: amd64
pkg: map-bench
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkInsertIntoEmptyMapCompoundKey-8         1000000  332.2 ns/op
BenchmarkInsertIntoPreallocatedMapCompoundKey-8  1000000  177.7 ns/op
PASS
```

## Memory requirements

- For us much more relevant
    - as pods might be killed due to OOM
    - and we have to pay for more memory

## Go profiler to the rescue

![Profiler2](images/profiler2.png)

## Go profiler to the rescue

![Profiler3](images/profiler3.png)

## Set implementations

- Implementation
    - first devel instinct: "map" of course
    - but we tried linear data structure too!

## Set implementations (1/2)

```go
type ID int
 
func genID(i int) ID {
        return ID(3*i + 1)
}
 
func fillInMap(b *testing.B, items int) map[ID]struct{} {
        b.StopTimer()
 
        m := make(map[ID]struct{}, items)
 
        for i := 0; i < items; i++ {
                id := genID(i)
                m[id] = struct{}{}
        }
 
        b.StartTimer()
        return m
}
```

## Set implementations (2/2)

```go
 
func fillInSlice(b *testing.B, items int) []ID {
        b.StopTimer()
 
        s := make([]ID, items)
 
        for i := 0; i < items; i++ {
                id := genID(i)
                s[i] = id
        }
 
        b.StartTimer()
        return s
}
```

## Benchmark for read/in-set operation

```go
func performBenchmarkFindInMap(b *testing.B, m map[ID]struct{}) {
        items := len(m)
        for i := 0; i < b.N; i++ {
                _, found := m[genID(i%items)]
                if !found {
                        b.Fatal("not found")
                }
        }
}
```
 
## Benchmark for read/in-set operation

```go
func performBenchmarkFindInSlice(b *testing.B, s []ID) {
        items := len(s)
        for i := 0; i < b.N; i++ {
                found := false
                id := genID(i % items)
                for _, p := range s {
                        if p == id {
                                found = true
                                break
                        }
                }
                if !found {
                        b.Fatal("not found")
                }
        }
}
```

## Benchmark results

```
BenchmarkFindInMap1-8       100000000   12.01 ns/op
BenchmarkFindInSlice1-8     100000000    7.208 ns/op
BenchmarkFindInMap5-8       100000000   12.61 ns/op
BenchmarkFindInSlice5-8     100000000    8.346 ns/op
BenchmarkFindInMap10-8      100000000   14.57 ns/op
BenchmarkFindInSlice10-8    100000000    9.498 ns/op
BenchmarkFindInMap20-8      100000000   14.28 ns/op
BenchmarkFindInSlice20-8    100000000   11.61 ns/op
BenchmarkFindInMap100-8     100000000   14.63 ns/op
BenchmarkFindInSlice100-8   100000000   35.57 ns/op
BenchmarkFindInMap1000-8    100000000   22.53 ns/op
BenchmarkFindInSlice1000-8  100000000  281.4 ns/op
```

## Graphical interpretation

## Low number of items

![Set1](images/set1.png)

## Higher number of items

![Set2](images/set2.png)

## Map vs slice for set implementation

![Set3](images/set3.png)

## Use slices instead of arrays (if possible)

- C-proselytes and Java-proselytes seems to use arrays a lot
- But in fact arrays are not used much in idiomatic Go code

- Array in Go
    - passed by value (COPY!)
    - not the case in C/Java/Python
    - semantic is totally different

## Slices in Go

- Struct/record with three items
   - pointer to data (array)
   - length
   - capacity
- Passed by value
   - but it is not deep clone

## Benchmark (1/4)

```go
func changeMe1(values []int) {
	values[0] = FIRST_VALUE
	values[MAX_VALS-1] = LAST_VALUE
}

func changeMe2(values [MAX_VALS]int) {
	values[0] = FIRST_VALUE
	values[MAX_VALS-1] = LAST_VALUE
}

func changeMe3(values *[MAX_VALS]int) {
	values[0] = FIRST_VALUE
	values[MAX_VALS-1] = LAST_VALUE
}
```

## Benchmark (2/4)

```go
func BenchmarkPassSlice(b *testing.B) {
	var values []int = make([]int, MAX_VALS)

	for i := 0; i < b.N; i++ {
		changeMe1(values)
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark (3/4)

```go
func BenchmarkPassArrayByValue(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		changeMe2(values)
	}
	if values[0] != DEFAULT_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != DEFAULT_VALUE {
		b.Fatal()
	}
}

## Benchmark (4/4)

```go
func BenchmarkPassArrayByReference(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		changeMe3(&values)
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark results

```
BenchmarkPassSlice-8              100000000    0.4799 ns/op
BenchmarkPassArrayByValue-8       100000000    0.2371 ns/op
BenchmarkPassArrayByReference-8   100000000    0.4740 ns/op
```

- What?
    - compiler detected that local changes are not visible outside function
    - and the whole function was dropped

## Is it really the case?

![Profiler4](images/profiler4.png)

## Now with side effect

```go
func changeMe1(values []int) int {
        values[0] = FIRST_VALUE
        values[MAX_VALS-1] = LAST_VALUE
        return values[MAX_VALS/2]
}

func changeMe2(values [MAX_VALS]int) int {
        values[0] = FIRST_VALUE
        values[MAX_VALS-1] = LAST_VALUE
        return values[MAX_VALS/2]
}

func changeMe3(values *[MAX_VALS]int) int {
        values[0] = FIRST_VALUE
        values[MAX_VALS-1] = LAST_VALUE
        return values[MAX_VALS/2]
}
```

## Benchmark (1/3)

```
func BenchmarkPassSlice(b *testing.B) {
	var values []int = make([]int, MAX_VALS)

	for i := 0; i < b.N; i++ {
		r := changeMe1(values)
		if r != DEFAULT_VALUE {
			b.Fatal()
		}
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark (2/3)

```
func BenchmarkPassArrayByValue(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		r := changeMe2(values)
		if r != DEFAULT_VALUE {
			b.Fatal()
		}
	}
	if values[0] != DEFAULT_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != DEFAULT_VALUE {
		b.Fatal()
	}
}
```

## Benchmark (3/3)

```
func BenchmarkPassArrayByReference(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		r := changeMe3(&values)
		if r != DEFAULT_VALUE {
			b.Fatal()
		}
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark results

```
BenchmarkPassSlice-8              100000000    0.4768 ns/op
BenchmarkPassArrayByValue-8       100000000  135.3 ns/op
BenchmarkPassArrayByReference-8   100000000    0.5629 ns/op
```
## Benchmark results

![benchmark3](images/benchmark3.png)

## for-each implementation (arrays, slices)

- idiomatic
- more performant

## for-each implementations

```go
for _, item := range items {
        sum += item.value
}
```

```go
for j := 0; j < len(items); j++ {
        sum += items[j].value
}
```

## Benchmark results

```
BenchmarkCountValues1-8   100000  70310 ns/op
BenchmarkCountValues2-8   100000  10687 ns/op
```
## Benchmark results

![benchmark4](images/benchmark4.png)

## for-each implementation (maps)

- idiomatic
- more performant

## for-each implementations

```go
for key, value := range items {
        ...
}
```

```go
for key, _ := range items {
        ...
        items[key]
        ...
}
```

## Benchmark results

```
BenchmarkCountValues1-8   100000   144225 ns/op
BenchmarkCountValues2-8   100000    12300 ns/op
```

## Benchmark results

![benchmark5](images/benchmark5.png)

## Synchronization

- using channels
- using mutexes

## Synchronization by mutexes

```go
func (value *valueWithMutex) lock() {
        value.mutex.Lock()
}

func (value *valueWithMutex) unlock() {
        value.mutex.Unlock()
}
```

## Synchronization by using channel

```go
func (value *valueWithChannel) lock() {
    // blocking
    <-value.channel
}

func (value *valueWithChannel) unlock() {
    value.channel <- struct{}{}
}
```

## Benchmarks

```
BenchmarkMutexVariant-8     100000  29044 ns/op
BenchmarkChannelVariant-8   100000  49570 ns/op
```

## String builders

- very frequent operation
    - templates
    - JSON and XML serializers
- usually 'hidden' inside libraries

## Strings are immutable

```go
type stringStruct struct {
        str unsafe.Pointer
        len int
}
```

## String concatenation is slow

```go
func concatstrings(buf *tmpBuf, a []string) string {
        idx := 0
        l := 0
        count := 0
        for i, x := range a {
                n := len(x)
                if n == 0 {
                        continue
                }
                if l+n < l {
                        throw("string concatenation too long")
                }
                l += n
                count++
                idx = i
        }
        if count == 0 {
                return ""
        }

        // If there is just one string and either it is not on the stack
        // or our result does not escape the calling frame (buf != nil),
        // then we can return that string directly.
        if count == 1 && (buf != nil || !stringDataOnStack(a[idx])) {
                return a[idx]
        }
        s, b := rawstringtmp(buf, l)
        for _, x := range a {
                copy(b, x)
                b = b[len(x):]
        }
        return s
}
```

## So how to append strings?

```go
s := ""

for i := 0; i < n; i++ {
        s += "*"
}
```

## Bytes buffer object

```go
var bb bytes.Buffer

for i := 0; i < n; i++ {
        bb.WriteRune('*')
}

return bb.String()
```

## String builder object

```go
var sb strings.Builder

for i := 0; i < n; i++ {
        sb.WriteRune('*')
}

return sb.String()
```

## Memory pre-allocation (buffer)

```go
var bb bytes.Buffer

bb.Grow(n)

for i := 0; i < n; i++ {
        bb.WriteRune('*')
}

return bb.String()
```

## Memory pre-allocation (builder)

```go
var bb bytes.Builder

bb.Grow(n)

for i := 0; i < n; i++ {
        bb.WriteRune('*')
}

return bb.String()
```

## Benchmark results

![benchmark6](images/benchmark6.png)

## Benchmark results

![benchmark7](images/benchmark7.png)

## Benchmark results

![benchmark8](images/benchmark8.png)

## SIMD instructions

- Sets of special instructions
    - operate on short fixed-length arrays
    - specialized data-processing operations
    - (not available outside SIMD world)
    - min, max, abs, saturated arithmetic
- Very important feature of today CPUs
    - sometimes more important than multicore(s)

## SIMD extensions on x86-64 CPUs

- MMX
- 3Dnow!
- SSE
    - SSE 2, SSE 3, SSE 4.1, SSE 4.2
- AVX
    - splitted into multiple sets
    - F16C etc.

## How are these used?

- Auto-vectorization
    - performed by compiler
- Intrinsic
    - available made by compiler/headers/packages
- Assembler
    - built-in (if available)
    - external one

## Typical vectors used in SIMD

![SIMD](images/simd.png)

## Operations with vectors (GCC)

```c
typedef signed int v16si __attribute__((vector_size(16)));
 
void add16ui(v16si x, v16si y, v16si - z)
{
    *z = x + y;
}

v16si x = { 0, 1, 2, 3 };
v16si y = { 0xffffffff, 0xffffffff, 0xffffffff, 0xffffffff };
v16si z;

add16ui(x, y,  z);

int i;

puts("vector of signed ints");

for (i = 0; i < sizeof(v16si) / sizeof(signed int); i++) {
    printf("%d %d\n", i, z[i]);
}
```

## Intrinsic

```
Technology  Header file
--
MMX         mmintrin.h
SSE1        xmmintrin.h
SSE2        emmintrin.h
SSE4.1      smmintrin.h
AVX2        avx2intrin.h
```

## Intrinsic usage

```c
 #include <xmmintrin.h>
 
int main(void)
{
    __v4sf x = { 1.0, 2.0, 3.0, 4.0 };
    __v4sf y = { 0.1, 0.1, 0.1, 0.1 };
    __v4sf z;
    int i;
 
    z = __builtin_ia32_addps(x, y);
 
    for (i = 0; i < sizeof(x) / sizeof(float); i++) {
        printf("%2d %f %f %f\n", i, x[i], y[i], z[i]);
    }
}
```

## Generated machine code

```asm
   z = __builtin_ia32_addps(x, y);
  31:   0f 28 45 d0             movaps xmm0,XMMWORD PTR [rbp-0x30]
  35:   0f 28 4d c0             movaps xmm1,XMMWORD PTR [rbp-0x40]
  39:   0f 58 c1                addps  xmm0,xmm1
  3c:   0f 29 45 e0             movaps XMMWORD PTR [rbp-0x20],xmm0
```

## SIMD support in Go

- Auto-vectorization
    - not provided by Google's compiler
    - gccgo can use it
- Intrinsic
    - not available in Go
    - and very probably never will!
- Assembler
    - built-in N/A in Go
    - external one is cumbersome to use
    - gccgo + GNU assembler (gas)

## SIMD support in Go

- Not ideal situation today
    - we don't invest into this approach
    - anyway most processing is performed against UTF-8 chars

# Thank you!
## CGo?

- C and Go, Cgo, but not a Go
- allows  interoperability between Go and C code
- calling C function in Go and Go functions in C
- "FFI"
- "C" "meta" package

## CGo

- has overhead, look for solution in Go
- C code can't hold pointers in to the Go world
- ^^ due to the copying nature of the GC
- need to manually free malloc'ed(heap) C memory
- string, arrays and such

## Example C in Go inline

.code assets/lecture-06/cgo-inlinec/cgo-inlinec.go

## Example C in Go separate files

.code assets/lecture-06/cgo-independent/cgo-independent.go

## Example memory management with CGo and C strings

.code assets/lecture-06/cgo-strings/cgo-string.go /memory management/,/memory management end/

## Example Go in C

- don't
- again don't
- look at the CGo docs
- BEWARE! it has extreme overhead

## Builtin tools

- go vet
- reports suspicions code construct, possible bugs
- go fmt
- formates code to the common coding standard
- go fix
- forward ports your code to latest release version of Go

## External tools

- abcgo
- gosec
- gocyclo
- goconst
- (go)errcheck
- gocritic

## Dependency management

## The Past

- go get and GOPATH
- vendoring aka bundling
- plethora of tools, godep, govendor, glide

## The Present

- Go modules, go mod
- local cache instead of GOPATH
- go mod
- go.mod storing informations for module
- init, vendor, download
- go get bar@...
- go list -m
- go list -u -m -json all
- go list -u -m -json all | go-mod-outdated -update

## Proxies and sumdbs

- Proxies facilitates fetches, instead of direct
- SumDBs hashes of repos for corresponding versions

## Generics in Go

## Why generics?

- to be able to create something similar to Numpy in Go
- true abstract data types
- lists
- trees
- priority queues
- ...

## Non-generic functions

.play assets/lecture-06/01_print.go

## Overloaded function in Go?

.play assets/lecture-06/02_print_overload.go

## No automatic type conversions

.play assets/lecture-06/03_print_no_conversion.go

## Generics implemented in runtime

.play assets/lecture-06/04_print_interface.go

## Generic function

.play assets/lecture-06/05_generic_print.go

## Selection of generic function

.play assets/lecture-06/06_type_parameter.go

## Compilation type checks

.play assets/lecture-06/07_type_parameter_check.go

## Concrete comparable interface

.play assets/lecture-06/08_comparable.go

## Problem with overloading

.play assets/lecture-06/09_comparable_variable_types.go

## Generic comparable interface

.play assets/lecture-06/10_compare_type_parameters.go

## Compile time or runtime?

- Python

.code assets/lecture-06/Test.py

## Compile time or runtime?

- Python

.code assets/lecture-06/Test.py.asm

## Compile time or runtime?

- Java

.code assets/lecture-06/Test.java

## Compile time or runtime?

.code assets/lecture-06/Test.java.asm / public static void main/,/^}/

## Generic comparable interface (again)

.play assets/lecture-06/10_compare_type_parameters.go

## Compile time or runtime?

- go
- interface{} - runtime
- type parameters - compile time

 $ go tool compile -S 08_comparable.go > 08_comparable.s
 $ go tool compile -S 10_compare_type_parameters.go > 10_compare_type_parameters.s

## Compiled concrete function

  "".compare STEXT nosplit size=7 args=0x10 locals=0x0 funcid=0x0 align=0x0
        0x0000 00000 (08_comparable.go:7)       TEXT    "".compare(SB), NOSPLIT|ABIInternal, $0-16
        0x0000 00000 (08_comparable.go:7)       PCDATA  $3, $1
        0x0000 00000 (08_comparable.go:8)       CMPQ    BX, AX
        0x0003 00003 (08_comparable.go:8)       SETGT   AL
        0x0006 00006 (08_comparable.go:8)       RET

## Compiled generic function

  "".compare[go.shape.int_0] STEXT dupok nosplit size=7 args=0x18 locals=0x0 funcid=0x0 align=0x0
        0x0000 00000 (10_compare_type_parameters.go:11) TEXT    "".compare[go.shape.int_0](SB), DUPOK|NOSPLIT|ABIInternal, $0-24
        0x0000 00000 (10_compare_type_parameters.go:11) PCDATA  $3, $1
        0x0000 00000 (10_compare_type_parameters.go:12) CMPQ    CX, BX
        0x0003 00003 (10_compare_type_parameters.go:12) SETGT   AL
        0x0006 00006 (10_compare_type_parameters.go:12) RET
  "".compare[go.shape.float64_0] STEXT dupok nosplit size=8 args=0x18 locals=0x0 funcid=0x0 align=0x0
        0x0000 00000 (10_compare_type_parameters.go:11) TEXT    "".compare[go.shape.float64_0](SB), DUPOK|NOSPLIT|ABIInternal, $0-24
        0x0000 00000 (10_compare_type_parameters.go:11) PCDATA  $3, $1
        0x0000 00000 (10_compare_type_parameters.go:12) UCOMISD X0, X1
        0x0004 00004 (10_compare_type_parameters.go:12) SETHI   AL
        0x0007 00007 (10_compare_type_parameters.go:12) RET
  "".compare[go.shape.string_0] STEXT dupok size=120 args=0x28 locals=0x28 funcid=0x0 align=0x0
        0x0000 00000 (10_compare_type_parameters.go:11) TEXT    "".compare[go.shape.string_0](SB), DUPOK|ABIInternal, $40-40
        0x0000 00000 (10_compare_type_parameters.go:11) CMPQ    SP, 16(R14)
        0x0004 00004 (10_compare_type_parameters.go:11) PCDATA  $0, $-2
        0x0004 00004 (10_compare_type_parameters.go:11) JLS     63
        ...
        ...
        0x002a 00042 (10_compare_type_parameters.go:12) PCDATA  $1, $1
        0x002a 00042 (10_compare_type_parameters.go:12) CALL    runtime.cmpstring(SB)
        ...
        ...
        0x003e 00062 (10_compare_type_parameters.go:12) RET

## "Universal numeric" data type?

.play assets/lecture-06/11_add_int.go

## "Universal numeric" data type?

.play assets/lecture-06/12_add_type_parameters.go

## No automatic type conversion (1/2)

.play assets/lecture-06/13_add_type_parameters.go /^package main/,/^func main/

## No automatic type conversion (2/2)

.play assets/lecture-06/13_add_type_parameters.go /^func main/,/^}/

## Type approximations (1/2)

.play assets/lecture-06/14_add_type_parameters.go /^package main/,/^func main/

## Type approximations (2/2)

.play assets/lecture-06/14_add_type_parameters.go /^func main/,/^}/

## Concrete "pow" function

.play assets/lecture-06/21_pow_floats_B.go

## Generic "pow" function

.play assets/lecture-06/22_pow_generic_B.go

## Generic method vs. generic function

.play assets/lecture-06/34_whats_better.go

## Generic linked list implementation

.play assets/lecture-06/35_list.go
