# Performance, CGo, Unsafe & Reflection
Course Go
Tags: golang, go

## Outline

- Benchmarks
- Optimizations
    - References & Values
    - Maps
    - Slices
    - For-each loops
    - Strings
- CGo
- Unsafe
- Reflection

## Benchmarks

## Benchmarks

- Part of standard Go tooling
- Benchmarks are a part of the test files
- Each benchmark is also a function that has to:
    - Start with the **`Benchmark`** prefix
    - Take in a single armung of type **`*testing.B`**

[Go Packages: testing benchmarks](https://pkg.go.dev/testing#hdr-Benchmarks)

## The B type

- Like the **`*testing.T`** type, the **`*testing.B`** is used to interact with the benchmark
    - It extends the testing type with additional methods
- **`N`**: exposes number of runs for the benchmark
- **`StartTimer`**: starts the benchmark timer
- **`StopTimer`**: stops the benchmark timer
- **`ResetTimer`**: resets the benchmark timer
- **`Elapsed`**: returns elapsed time
- **`ReportAllocs`**: enables malloc statistics
- And a few more...

[Go Packages: testing B type](https://pkg.go.dev/testing#B)

## Running benchmarks

- Benchmarks are run via the **`go test`** subcommand
    - With the **`-bench`** option
        - Requires path or regex for benchmark name
- Related options include:
    - **`-count`**: specifies how many times the benchmark is run
    - **`-benchtime`**: sets minimum amount of time
        - 1s by default
    - **`-benchmem`**: prints memory allocation statistics
- Example usage:

```
$ go test -bench Slice -benchmem -count 5 -benchtime 3s
```

## Slice benchmark

.code assets/lecture-06/benchmarks/slices_test.go /START OMIT/,/END OMIT/

## Benchmark output

.code assets/lecture-06/benchmarks/slices-out.txt

## Benchstat

- Tool for computing statistical summaries
    - Parses benchmark output
- Allows comparing benchmark runs
- Can be installed like so:

```
$ go install golang.org/x/perf/cmd/benchstat@latest
```

[Go Packages: benchstat](https://pkg.go.dev/golang.org/x/perf/cmd/benchstat)

## Benchstat usage

- Output the benchmark to separate file:

```
$ go test -bench Slice -benchmem -count 10 | tee out.txt
```

- Examine benchmark:

```
$ benchstat out.txt
```

- Compare benchmark runs:

```
$ benchstat old.txt new.txt
```

## Benchstat output

```
goos: darwin
goarch: arm64
pkg: github.com/course-go/lectures/assets/lecture-06/benchmarks
                             │   out.txt   │
                             │   sec/op    │
SliceCreation-12               2.445m ± 2%
SliceCreationPreallocated-12   511.1µ ± 0%
geomean                        1.118m

                             │   out.txt    │
                             │     B/op     │
SliceCreation-12               39.75Mi ± 0%
SliceCreationPreallocated-12   7.633Mi ± 0%
geomean                        17.42Mi

                             │  out.txt   │
                             │ allocs/op  │
SliceCreation-12               39.00 ± 0%
SliceCreationPreallocated-12   1.000 ± 0%
geomean                        6.245
```

## Timers

.code assets/lecture-06/benchmarks/timers_test.go /START OMIT/,/END OMIT/

## Profiling

## Profiling

- TODO

## Memory profile

- go test -bench=. -benchmem -memprofile profile.out
- go tool pprof profile.out
- go tool pprof -web profile.out
- go tool pprof -http localhost:8080 profile.out

## CPU profile

- go test -bench=. -benchmem -cpuprofile profile.out
- go tool pprof profile.out
- go tool pprof -web profile.out
- go tool pprof -http localhost:8080 profile.out

## Optimizations

## Optimizations

- Go compiler is pretty straightfoward (= dumb)
- It needs some help from developers

## Some interesting areas backed by experience

1. _"Pass structures by reference, not by value"_
2. _"Pass receivers by reference, not by value"_
3. _"Maps & slides pre-allocation"_
4. _"Arrays vs slices"_

- Most things mentioned are unidiomatic!

## Pass structures by reference, not by value

- All data types are passed by value into functions and methods
    - Good from "state-space" perspective
    - Not so good from performance point of view
- Problem definition:
    - Large structures passed by value everywhere in the code
    - Even within inner loops
    - It causes overhead that is easy to avoid
        - But at cost: wrong semantic is used

## Large config (1/3)

.code assets/lecture-06/optimizations/config.toml /START OMIT/,/END OMIT/

## Large config (2/3)

.code assets/lecture-06/optimizations/config.go /^type Config/,/^}/

.code assets/lecture-06/optimizations/config.go /^type StorageConfiguration/,/^}/

## Large config (3/3)

.code assets/lecture-06/optimizations/config.go /^type KafkaConfiguration/,/^}/

## Config getter

.code assets/lecture-06/optimizations/config.go /VALUE START OMIT/,/VALUE END OMIT/

- Config is passed by value
- Pros:
    - Pretty idiomatic
    - Basically declares that the structure is immutable
- Cons:
    - The config is always copied
        - Structure size is about 700 bytes!

## Dirty solution

.code assets/lecture-06/optimizations/config.go /REFERENCE START OMIT/,/REFERENCE END OMIT/

- The only possible solution in Go
    - Different semantic:
        - Passing by reference implies that the struct can be changed within
- Unfortunately we can't distinguish between `const` and `mut`
    - Mutation (or the lack of it) has to be checked by unit tests

## Benchmark helper functions

.code assets/lecture-06/optimizations/config_test.go /HELPER START OMIT/,/HELPER END OMIT/

## Benchmarks

.code assets/lecture-06/optimizations/config_test.go /BENCHMARK START OMIT/,/BENCHMARK MIDDLE OMIT/

## Benchmark results

```
$ go test -bench=Function -benchtime=1000000000x -cpuprofile profile.out
```

```
goos: linux
goarch: amd64
pkg: config-struct/conf
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkGetStorageConfigurationFunctionByValue
BenchmarkGetStorageConfigurationFunctionByValue-8       1000000000  13.20 ns/op
BenchmarkGetStorageConfigurationFunctionByReference
BenchmarkGetStorageConfigurationFunctionByReference-8   1000000000   0.2405 ns/op
PASS
ok      config-struct/conf      27.166s
```

- 13.20 ns/op vs 0.2405 ns/op
- That is 5488% speed increase
    - `memcpy` operation elimination

## Graphical output

.image assets/lecture-06/benchmark1.png 520 _

## Table output

.image assets/lecture-06/benchmark2.png 250 _

## What about methods?

- The same issue and simple fix

.code assets/lecture-06/optimizations/config.go /RECEIVER START OMIT/,/RECEIVER END OMIT/

## Benchmark for methods

.code assets/lecture-06/optimizations/config_test.go /BENCHMARK MIDDLE OMIT/,/BENCHMARK END OMIT/

## Run the benchmark

```
$ go test -bench=Method -benchtime=1000000000x -cpuprofile profile.out
```

```
goos: linux
goarch: amd64
pkg: config-struct/conf
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkGetStorageConfigurationMethodByValue
BenchmarkGetStorageConfigurationMethodByValue-8        1000000000   13.24 ns/op
BenchmarkGetStorageConfigurationMethodByReference
BenchmarkGetStorageConfigurationMethodByReference-8    1000000000    0.3596 ns/op
PASS
ok      config-struct/conf      27.166s
```

- Pretty much the same result

## Maps

## Maps pre-allocation

- Map allocations via `make` allows to specify expected number of map items

```
m1 := make(map[uuid.UUID]time.Time)
m2 := make(map[uuid.UUID]time.Time, 1000)
```

- Not strictly needed
    - Developers tend to ignore it
- Does it even make sense to try to estimate number of items?
    - Who knows? Probably only the benchmark...

## Benchmark

.code assets/lecture-06/optimizations/maps_test.go /UUID START OMIT/,/UUID END OMIT/

## Benchmark results

```
goos: linux
goarch: amd64
pkg: map-bench
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkInsertIntoEmptyMapUUIDKey-8            1000000   354.7 ns/op
BenchmarkInsertIntoPreallocatedMapUUIDKey-8     1000000   163.9 ns/op
PASS
```

## Graphical output

.image assets/lecture-06/profiler1.png 500 _

## Maps with large keys

- Keys can be of any type in Go
- So keys might be pretty large
    - Imagine structs



.code assets/lecture-06/optimizations/maps_test.go /COMPOUND-KEY-VALUE START OMIT/,/COMPOUND START OMIT/

```
m1 := make(map[key]value)
m2 := make(map[key]value, capacity)
```

## Benchmark

.code assets/lecture-06/optimizations/maps_test.go /COMPOUND START OMIT/,/COMPOUND END OMIT/

## Benchmark results for maps with large keys

```
goos: linux
goarch: amd64
pkg: map-bench
cpu: Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz
BenchmarkInsertIntoEmptyMapCompoundKey-8         1000000  332.2 ns/op
BenchmarkInsertIntoPreallocatedMapCompoundKey-8  1000000  177.7 ns/op
PASS
```

## Memory requirements

- For us much more relevant
    - Pods might be killed due to OOM
    - Additional memory has to be bought

## Go profiler to the rescue

.image assets/lecture-06/profiler2.png 420 _

## Go profiler to the rescue

.image assets/lecture-06/profiler3.png 500 _

## Set implementations

- First devel instinct
    - The usage of `map` of course
- But linear data structure can be used too!

## Set implementations (1/2)

```go
type ID int
 
func genID(i int) ID {
        return ID(3*i + 1)
}
 
func fillInMap(b *testing.B, items int) map[ID]struct{} {
        b.StopTimer()
 
        m := make(map[ID]struct{}, items)
 
        for i := 0; i < items; i++ {
                id := genID(i)
                m[id] = struct{}{}
        }
 
        b.StartTimer()
        return m
}
```

## Set implementations (2/2)

```go
 
func fillInSlice(b *testing.B, items int) []ID {
        b.StopTimer()
 
        s := make([]ID, items)
 
        for i := 0; i < items; i++ {
                id := genID(i)
                s[i] = id
        }
 
        b.StartTimer()
        return s
}
```

## Benchmark for read/in-set operation

```go
func performBenchmarkFindInMap(b *testing.B, m map[ID]struct{}) {
        items := len(m)
        for i := 0; i < b.N; i++ {
                _, found := m[genID(i%items)]
                if !found {
                        b.Fatal("not found")
                }
        }
}
```
 
## Benchmark for read/in-set operation

```go
func performBenchmarkFindInSlice(b *testing.B, s []ID) {
        items := len(s)
        for i := 0; i < b.N; i++ {
                found := false
                id := genID(i % items)
                for _, p := range s {
                        if p == id {
                                found = true
                                break
                        }
                }
                if !found {
                        b.Fatal("not found")
                }
        }
}
```

## Benchmark results

```
BenchmarkFindInMap1-8       100000000   12.01 ns/op
BenchmarkFindInSlice1-8     100000000    7.208 ns/op
BenchmarkFindInMap5-8       100000000   12.61 ns/op
BenchmarkFindInSlice5-8     100000000    8.346 ns/op
BenchmarkFindInMap10-8      100000000   14.57 ns/op
BenchmarkFindInSlice10-8    100000000    9.498 ns/op
BenchmarkFindInMap20-8      100000000   14.28 ns/op
BenchmarkFindInSlice20-8    100000000   11.61 ns/op
BenchmarkFindInMap100-8     100000000   14.63 ns/op
BenchmarkFindInSlice100-8   100000000   35.57 ns/op
BenchmarkFindInMap1000-8    100000000   22.53 ns/op
BenchmarkFindInSlice1000-8  100000000  281.4 ns/op
```

## Graphical interpretation

## Low number of items

.image assets/lecture-06/set1.png 500 _

## Higher number of items

.image assets/lecture-06/set2.png 500 _

## Map vs slice for set implementation

.image assets/lecture-06/set3.png 500 _

## Slices

## Use slices instead of arrays (if possible)

- C-proselytes and Java-proselytes seems to use arrays a lot
- But in fact arrays are not used much in idiomatic Go code

- Array in Go
    - passed by value (COPY!)
    - not the case in C/Java/Python
    - semantic is totally different

## Slices in Go

- Struct/record with three items
   - pointer to data (array)
   - length
   - capacity
- Passed by value
   - but it is not deep clone

## Benchmark (1/4)

```go
func changeMe1(values []int) {
	values[0] = FIRST_VALUE
	values[MAX_VALS-1] = LAST_VALUE
}

func changeMe2(values [MAX_VALS]int) {
	values[0] = FIRST_VALUE
	values[MAX_VALS-1] = LAST_VALUE
}

func changeMe3(values *[MAX_VALS]int) {
	values[0] = FIRST_VALUE
	values[MAX_VALS-1] = LAST_VALUE
}
```

## Benchmark (2/4)

```go
func BenchmarkPassSlice(b *testing.B) {
	var values []int = make([]int, MAX_VALS)

	for i := 0; i < b.N; i++ {
		changeMe1(values)
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark (3/4)

```go
func BenchmarkPassArrayByValue(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		changeMe2(values)
	}
	if values[0] != DEFAULT_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != DEFAULT_VALUE {
		b.Fatal()
	}
}

## Benchmark (4/4)

```go
func BenchmarkPassArrayByReference(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		changeMe3(&values)
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark results

```
BenchmarkPassSlice-8              100000000    0.4799 ns/op
BenchmarkPassArrayByValue-8       100000000    0.2371 ns/op
BenchmarkPassArrayByReference-8   100000000    0.4740 ns/op
```

- What?
    - compiler detected that local changes are not visible outside function
    - and the whole function was dropped

## Is it really the case?

.image assets/lecture-06/profiler4.png 450 _

## Now with side effect

```go
func changeMe1(values []int) int {
        values[0] = FIRST_VALUE
        values[MAX_VALS-1] = LAST_VALUE
        return values[MAX_VALS/2]
}

func changeMe2(values [MAX_VALS]int) int {
        values[0] = FIRST_VALUE
        values[MAX_VALS-1] = LAST_VALUE
        return values[MAX_VALS/2]
}

func changeMe3(values *[MAX_VALS]int) int {
        values[0] = FIRST_VALUE
        values[MAX_VALS-1] = LAST_VALUE
        return values[MAX_VALS/2]
}
```

## Benchmark (1/3)

```go
func BenchmarkPassSlice(b *testing.B) {
	var values []int = make([]int, MAX_VALS)

	for i := 0; i < b.N; i++ {
		r := changeMe1(values)
		if r != DEFAULT_VALUE {
			b.Fatal()
		}
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark (2/3)

```go
func BenchmarkPassArrayByValue(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		r := changeMe2(values)
		if r != DEFAULT_VALUE {
			b.Fatal()
		}
	}
	if values[0] != DEFAULT_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != DEFAULT_VALUE {
		b.Fatal()
	}
}
```

## Benchmark (3/3)

```go
func BenchmarkPassArrayByReference(b *testing.B) {
	var values [MAX_VALS]int = [MAX_VALS]int{DEFAULT_VALUE}

	for i := 0; i < b.N; i++ {
		r := changeMe3(&values)
		if r != DEFAULT_VALUE {
			b.Fatal()
		}
	}
	if values[0] != FIRST_VALUE {
		b.Fatal()
	}
	if values[MAX_VALS-1] != LAST_VALUE {
		b.Fatal()
	}
}
```

## Benchmark results

```go
BenchmarkPassSlice-8              100000000    0.4768 ns/op
BenchmarkPassArrayByValue-8       100000000  135.3 ns/op
BenchmarkPassArrayByReference-8   100000000    0.5629 ns/op
```

## Benchmark results

.image assets/lecture-06/benchmark3.png 500 _

## for-each implementation (arrays, slices)

- idiomatic
- more performant

## for-each implementations

```go
for _, item := range items {
        sum += item.value
}
```

```go
for j := 0; j < len(items); j++ {
        sum += items[j].value
}
```

## Benchmark results

```
BenchmarkCountValues1-8   100000  70310 ns/op
BenchmarkCountValues2-8   100000  10687 ns/op
```

## Benchmark results

.image assets/lecture-06/benchmark4.png 500 _

## for-each implementation (maps)

- idiomatic
- more performant

## for-each implementations

```go
for key, value := range items {
        ...
}
```

```go
for key, _ := range items {
        ...
        items[key]
        ...
}
```

## Benchmark results

```
BenchmarkCountValues1-8   100000   144225 ns/op
BenchmarkCountValues2-8   100000    12300 ns/op
```

## Benchmark results

.image assets/lecture-06/benchmark5.png 500 _

## Synchronization

## Synchronization

- Using channels
- Using mutexes

## Synchronization by mutexes

```go
func (value *valueWithMutex) lock() {
        value.mutex.Lock()
}

func (value *valueWithMutex) unlock() {
        value.mutex.Unlock()
}
```

## Synchronization by using channel

```go
func (value *valueWithChannel) lock() {
    // blocking
    <-value.channel
}

func (value *valueWithChannel) unlock() {
    value.channel <- struct{}{}
}
```

## Benchmarks

```
BenchmarkMutexVariant-8     100000  29044 ns/op
BenchmarkChannelVariant-8   100000  49570 ns/op
```

## Strings

## String builders

- Used for concatenation of strings
    - Very frequent operation
        - Templates
        - JSON and XML serializers
- Usually used inside libraries

## Strings are immutable

```go
type stringStruct struct {
        str unsafe.Pointer
        len int
}
```

- So how can one append strings?
    - Naive builder
        - String concatenation

.code assets/lecture-06/optimizations/builders.go /NAIVE OMIT/,/BYTES OMIT/

## Bytes buffer

- Default

.code assets/lecture-06/optimizations/builders.go /BYTES OMIT/,/BYTES-PREALLOCATED OMIT/

- With pre-allocation

.code assets/lecture-06/optimizations/builders.go /BYTES-PREALLOCATED OMIT/,/STRING OMIT/

## String builder

- Default

.code assets/lecture-06/optimizations/builders.go /STRING OMIT/,/STRING-PREALLOCATED OMIT/

- With pre-allocation

.code assets/lecture-06/optimizations/builders.go /STRING-PREALLOCATED OMIT/,/END OMIT/

## Benchmark results

.image assets/lecture-06/benchmark6.png 550 _

## Benchmark results

.image assets/lecture-06/benchmark7.png 550 _

## Benchmark results

.image assets/lecture-06/benchmark8.png 500 _

## CGo

## CGo

- C and Go, CGo
- Allows interoperability between Go and C
    - Go can call C code and vice versa 
- Foreign function interface
- Interactions via the C "meta" package

[Go Wiki: cgo](https://go.dev/wiki/cgo)

[Go Packages: cgo](https://pkg.go.dev/cmd/cgo)

## CGo

- Has extreme overhead
    - Look for solution in Go
- C code cannot hold pointers in to the Go world
    - Due to the nature of the GC
- Need to manually free heap allocated C memory
    - String, arrays and such
- Code is generated by the `import "C"` statement
    - Even blank lines cannot exist between the import and the C code

## Inlined C code

.play assets/lecture-06/cgo/inlined.go

## Importing C code from separate file

.code assets/lecture-06/cgo/independent.go

## Memory management with C strings

.play assets/lecture-06/cgo/strings.go /START OMIT/,/END OMIT/

## Should I use it then?

- Don't...
    - The disadvantages outweigh the advantages
        - Runtime overhead
        - Slower build time
        - Complicated builds
        - Cross compilation
        - More error prone
    - Rewriting existing C code is almost always the prefer way
        - Always look for existing Go solutions
- Thoroughly examine the CGo docs
- Again, it has an EXTREME overhead

## Unsafe

## Unsafe

- Unsafe operations
    - Not protected by the compatibility promise
- Steps around the type system of Go
- Allows to directly access memory

[Go Packages: unsafe](https://pkg.go.dev/unsafe)

## Unsafe

.play assets/lecture-06/unsafe/unsafe.go /START OMIT/,/END OMIT/

## Reflection

## Reflection

- Run-time reflection
- Allows to manipulate objects with arbitrary types

[Go Packages: reflect](https://pkg.go.dev/reflect)

## Reflection

.play assets/lecture-06/reflect/reflect.go /START OMIT/,/END OMIT/

[Go Blog: The Laws of Reflection](https://go.dev/blog/laws-of-reflection)

## Reflecting structures

.play assets/lecture-06/reflect/struct.go /START OMIT/,/END OMIT/

[Go Blog: The Laws of Reflection](https://go.dev/blog/laws-of-reflection)
